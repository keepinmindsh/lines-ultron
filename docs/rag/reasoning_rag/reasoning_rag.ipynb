{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install -q langchain langgraph langchain-docling langchain-qdrant langchain-text-splitters langgchain-ollama",
   "id": "9fa50c2a5cb66b76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "5fbd457cd303f03c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_ollamra import ChatOllama\n",
    "\n",
    "reasoning_llm = ChatOllama(\n",
    "    model=\"deepseek-r1:7b\",\n",
    "    stop=[\"</think>\"]\n",
    ")\n",
    "\n",
    "answer_llm = ChatOllama(\n",
    "    model=\"exaone3.5\",\n",
    "    temperature=0,\n",
    ")"
   ],
   "id": "30c74fa8be390cf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import Annotated, List, TypedDict, Literal\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# RAG 상태 정의\n",
    "class RAGState(TypedDict):\n",
    "    \"\"\"RAG 시스템의 상태를 정의합니다.\"\"\"\n",
    "    query: str # 사용자 정의\n",
    "    thinking: str # reasoning_llm이 생성한 사고 과정\n",
    "    document: List[Document] # 검색된 문서\n",
    "    answer: str # 최종 답변\n",
    "    messages: Annotated[List, add_messages]\n",
    "    mode: str"
   ],
   "id": "3f01e2011a953400"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "FILE_PATH = \"https://arxiv.org/pdf/2400.09869\"\n",
    "\n",
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=ExportType.MARKDOWN\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ],
   "id": "cd06f1c976fc0ad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[\n",
    "        (\"#\", \"Header_1\"),\n",
    "        (\"##\", \"Header_2\"),\n",
    "        (\"###\", \"Header_3\"),\n",
    "        (\"####\", \"Header_4\"),\n",
    "        (\"#####\", \"Header_5\"),\n",
    "        (\"######\", \"Header_6\"),\n",
    "    ]\n",
    ")\n",
    "splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
    "\n",
    "for d in splits[:3]:\n",
    "    print(f\"- {d.page_content}...\")\n",
    "print(\"...\")"
   ],
   "id": "4310035c0884c57f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(splits[12].page_content))"
   ],
   "id": "64274dced4ac1ee6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"bge-m3:latest\",\n",
    ")"
   ],
   "id": "acd4d07f52cfdb08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T23:43:37.155365Z",
     "start_time": "2025-04-10T23:43:37.152421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_qdrant import RetrievalMode\n",
    "\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"rag_collection_0228\",\n",
    "    retrieval_mode=RetrievalMode.DENSE,\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})"
   ],
   "id": "6a9f5c72f643424d",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected argument value expression (2818145918.py, line 8)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mcollection_name=\u001B[39m\n    ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m expected argument value expression\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T23:46:36.209250Z",
     "start_time": "2025-04-10T23:46:36.205779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-base\")\n",
    "compressor = CrossEncoderReranker(\n",
    "    model=model,\n",
    "    top_n=5\n",
    ")\n",
    "contextual_compressor = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever,\n",
    ")"
   ],
   "id": "5e4184a7dda25876",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2754928190.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mfrom langchain.re\u001B[39m\n                     ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "\n",
    "def classify_mode(state: RAGState) -> str:\n",
    "    \"\"\"사용자 정의 질문을 분류하는 함수입니다.\"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=state[\"query\"],\n",
    "                additional_kwargs={\"mode\": state[\"mode\"]}\n",
    "            )\n",
    "        ]\n",
    "    }\n"
   ],
   "id": "32542989b1c2e80"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
