{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35ca522",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b19a62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# update or install the necessary libraries\n",
    "%pip install --upgrade openai\n",
    "%pip install --upgrade langchain\n",
    "%pip install --upgrade langchain_community\n",
    "%pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c31469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d058cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ee0d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    \"\"\" set openai parameters\"\"\"\n",
    "\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model = params['model'],\n",
    "        messages = messages,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0cd94",
   "metadata": {},
   "source": [
    "# Basis Prompt \n",
    "\n",
    "기본적인 프롬프트 호출의 사례 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706820d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic example\n",
    "params = set_open_params()\n",
    "\n",
    "prompt = \"The sky is\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "072bf4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sky is a vast expanse that can vary in color, appearance, and mood depending on the time of day, weather conditions, and location. During the day, it often appears blue due to the scattering of sunlight, while at sunrise and sunset, it can display a stunning palette of oranges, pinks, and purples. At night, the sky reveals stars, planets, and sometimes the moon, creating a different kind of beauty. The sky is not only a backdrop for our earthly experiences but also a source of inspiration, wonder, and scientific inquiry. What specific aspect of the sky are you interested in?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c369bb",
   "metadata": {},
   "source": [
    "# Text Summarization\n",
    "\n",
    "- 자체 요약의 요건 \n",
    "  - 보안 문제 \n",
    "  - 자체 데이터 학습 \n",
    "  - 비용 문제 \n",
    "\n",
    "\"기본적으로 좋은 요약을 위해서는 품질이 좋은 데이터가 중요하다.\"\n",
    "\n",
    "## 활용 가능한 Tool\n",
    "\n",
    "- [vLLM](https://github.com/vllm-project/vllm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "652aef0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Antibiotics are medications that treat bacterial infections by killing bacteria or inhibiting their reproduction, but they are ineffective against viruses and inappropriate use can lead to antibiotic resistance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params(temperature=0.7)\n",
    "prompt = \"\"\"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance. \n",
    "\n",
    "Explain the above in one sentence:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1de65d",
   "metadata": {},
   "source": [
    "# Question Answering \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f096c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Mice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
    "\n",
    "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
    "\n",
    "Question: What was OKT3 originally sourced from?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcefd36",
   "metadata": {},
   "source": [
    "# Retrieval QA chain types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf6022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\\\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer. \\\n",
    "    Use three sentences maximum. Keep the answer as concise as possible. \\\n",
    "    Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead3e86",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ce4b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sentiment: Neutral"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Classify the text into neutral, negative or positive.\n",
    "\n",
    "Text: I think the food was okay.\n",
    "\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595ef45",
   "metadata": {},
   "source": [
    "# Role Playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49977af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Black holes are formed from the remnants of massive stars that undergo gravitational collapse at the end of their life cycles. The process typically involves several key stages:\n",
       "\n",
       "1. **Stellar Evolution**: A massive star, typically more than 20 times the mass of the Sun, undergoes nuclear fusion, converting hydrogen into helium and subsequently heavier elements. This process generates an outward pressure that counteracts gravitational forces.\n",
       "\n",
       "2. **Supernova Explosion**: When the star exhausts its nuclear fuel, it can no longer sustain the outward pressure. The core collapses under its own gravity, leading to a supernova explosion that ejects the outer layers of the star into space.\n",
       "\n",
       "3. **Gravitational Collapse**: If the remaining core is sufficiently massive (generally above about 2-3 solar masses), the gravitational forces become so strong that they overcome all other forces, leading to the formation of a black hole. At this point, the core collapses to an infinitely dense point known as a singularity, surrounded by an event horizon, which marks the boundary beyond which nothing can escape the gravitational pull.\n",
       "\n",
       "4. **Types of Black Holes**: There are several classes of black holes:\n",
       "   - **Stellar Black Holes**: Formed from the remnants"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
    "\n",
    "Human: Hello, who are you?\n",
    "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
    "Human: Can you tell me about the creation of blackholes?\n",
    "AI:\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c50696",
   "metadata": {},
   "source": [
    "# Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56048f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To retrieve all students from the Computer Science Department, you can use a SQL query that joins the `departments` table with the `students` table based on the `DepartmentId`. Here's the SQL query you can use:\n",
       "\n",
       "```sql\n",
       "SELECT s.StudentId, s.StudentName\n",
       "FROM students s\n",
       "JOIN departments d ON s.DepartmentId = d.DepartmentId\n",
       "WHERE d.DepartmentName = 'Computer Science';\n",
       "```\n",
       "\n",
       "In this query:\n",
       "- We're selecting the `StudentId` and `StudentName` from the `students` table (aliased as `s`).\n",
       "- We're joining the `departments` table (aliased as `d`) where the `DepartmentId` matches in both tables.\n",
       "- The `WHERE` clause filters the results to include only those students who are in the \"Computer Science\" department."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\\\"\\\"\\\"\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a MySQL query for all students in the Computer Science Department\\n\\\"\\\"\\\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a8992df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break the problem down into steps as requested.\n",
       "\n",
       "### Step 1: Identify the odd numbers\n",
       "From the group of numbers: 15, 32, 5, 13, 82, 7, 1, we identify the odd numbers.\n",
       "\n",
       "- 15 (odd)\n",
       "- 32 (even)\n",
       "- 5 (odd)\n",
       "- 13 (odd)\n",
       "- 82 (even)\n",
       "- 7 (odd)\n",
       "- 1 (odd)\n",
       "\n",
       "The odd numbers are: **15, 5, 13, 7, 1**.\n",
       "\n",
       "### Step 2: Add the odd numbers\n",
       "Now, let's add the identified odd numbers together.\n",
       "\n",
       "\\[\n",
       "15 + 5 + 13 + 7 + 1\n",
       "\\]\n",
       "\n",
       "We can do this step by step:\n",
       "\n",
       "1. \\( 15 + 5 = 20 \\)\n",
       "2. \\( 20 + 13 = 33 \\)\n",
       "3. \\( 33 + 7 = 40 \\)\n",
       "4. \\( 40 + 1 = 41 \\)\n",
       "\n",
       "### Step 3: Indicate whether the result is odd or even\n",
       "The total sum of the odd numbers is **41**.\n",
       "\n",
       "Now, let's check if 41 is odd or even:\n",
       "- An odd"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "\n",
    "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96afe23",
   "metadata": {},
   "source": [
    "# 문맥을 구분하는 방법에 대해서 \n",
    "\n",
    "Prompt를 작성할 때, 다양한 방법들을 이용해서 테스트가 필요한데, 그중에서 하나의 추천되는 방법은 Instruction 과 Context 를 구분하여 정리하는 방법이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964ba60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "¡¿Qué pasa, hoy?!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params(temperature=0.7)\n",
    "prompt = \"\"\"\n",
    "### Instruction ###\n",
    "Translate the text below to Spanish:\n",
    "Text: \"What's up, today!\"\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2aa65d",
   "metadata": {},
   "source": [
    "# 너무 많은 Prompt는? \n",
    "\n",
    "설명이 많은 Prompt 자체가 좋은 것은 아님. \n",
    "중요한 것은 좋은 형식과 설명이 잘 작성되어 있는 Prompt가 중요하다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76ee49",
   "metadata": {},
   "source": [
    "# 부정확성을 피하기 \n",
    "\n",
    "- 좋지 않은 프롬프트 \n",
    "\n",
    "```\n",
    "Explain the concept prompt engineering. Keep the explanation short, only a few sentences, and don't be too descriptive.\n",
    "```\n",
    "\n",
    "- 좀더 명확하고, 정확하고, 요점을 찍는 프롬프트 \n",
    "\n",
    "```\n",
    "Use 2-3 sentences to explain the concept of prompt engineering to a high school student.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd702a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "프롬프트 엔지니어링은 AI 모델, 특히 언어 모델에게 원하는 결과를 얻기 위해 입력 문장을 최적화하는 과정입니다. 이는 질문이나 지시문을 효과적으로 구성하여 모델의 반응을 조정하고 원하는 정보를 이끌어내는 기술입니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params(temperature=0.7)\n",
    "prompt = \"\"\"\n",
    "Explain the concept prompt engineering. Keep the explanation short, only a few sentences, and don't be too descriptive. use korean\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd50c3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "프롬프트 엔지니어링은 컴퓨터와 대화할 때 원하는 정보를 얻기 위해 질문이나 명령을 잘 구성하는 기술이에요. 이 과정에서 어떻게 질문을 하느냐에 따라 컴퓨터의 반응이나 결과가 달라질 수 있기 때문에, 효과적으로 의사소통하는 방법을 배우는 것이 중요해요."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params(temperature=0.7)\n",
    "prompt = \"\"\"\n",
    "Use 2-3 sentences to explain the concept of prompt engineering to a high school student for korean\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a4a9e5",
   "metadata": {},
   "source": [
    "# 하느냐, 하지 않느냐 \n",
    "\n",
    "하지 않을 것에 대해서 Prompt를 작성하는 것보다 할 것에 대해서 Prompt를 작성하는 것이 더 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19be981e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! How about \"Inception\"? It's a mind-bending thriller that combines elements of science fiction and heist genres, featuring stunning visuals and a complex storyline. If you're in the mood for something different, \"The Grand Budapest Hotel\" offers a whimsical and visually striking experience with a unique narrative style. Let me know if you'd like more recommendations!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params(temperature=0.7)\n",
    "prompt = \"\"\"\n",
    "The following is an agent that recommends movies to a customer. DO NOT ASK FOR INTERESTS. DO NOT ASK FOR PERSONAL INFORMATION.\n",
    "Customer: Please recommend a movie based on my interests.\n",
    "Agent:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecc164dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sorry, couldn't find a movie to recommend today."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params(temperature=0.7)\n",
    "prompt = \"\"\"\n",
    "The following is an agent that recommends movies to a customer. The agent is responsible to recommend a movie from the top global trending movies. It should refrain from asking users for their preferences and avoid asking for personal information. If the agent doesn't have a movie to recommend, it should respond \"Sorry, couldn't find a movie to recommend today.\".\n",
    "Customer: Please recommend a movie based on my interests.\n",
    "Agent:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aacfe28",
   "metadata": {},
   "source": [
    "# \"\"\" , ### 에 대해서 작성하기\n",
    "\n",
    "Summarize the text below as a bullet point list of the most important points.\n",
    "\n",
    "Text: \"\"\"\n",
    "{text input here}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "112adecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please provide the text you would like me to summarize."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params(temperature=0.7)\n",
    "prompt = \"\"\"\n",
    "Summarize the text below as a bullet point list of the most important points.\n",
    "\n",
    "Text: \"\n",
    "{text input here}\n",
    "\"\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15198fd",
   "metadata": {},
   "source": [
    "# 예시를 통해서 원하는 출력형식으로 지정하기 \n",
    "\n",
    "Extract the important entities mentioned in the text below. First extract all company names, then extract all people names, then extract specific topics which fit the content and finally extract general overarching themes\n",
    "\n",
    "Desired format:\n",
    "Company names: <comma_separated_list_of_company_names>\n",
    "People names: -||-\n",
    "Specific topics: -||-\n",
    "General themes: -||-\n",
    "\n",
    "Text: {text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46934c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Please provide the text you would like me to analyze for extracting the entities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = set_open_params(temperature=0.7)\n",
    "prompt = \"\"\"\n",
    "Extract the important entities mentioned in the text below. First extract all company names, then extract all people names, then extract specific topics which fit the content and finally extract general overarching themes\n",
    "\n",
    "Desired format:\n",
    "Company names: <comma_separated_list_of_company_names>\n",
    "People names: -||-\n",
    "Specific topics: -||-\n",
    "General themes: -||-\n",
    "\n",
    "Text: {text}\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(params, messages)\n",
    "IPython.display.Markdown(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4974115",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "> [Getting Started with Prompt Engineering](https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/notebooks/pe-lecture.ipynb)   \n",
    "> [Best Practices for prompt engineering with the OpenAI API](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
