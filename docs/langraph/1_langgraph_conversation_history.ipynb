{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ed2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# update or install the necessary libraries\n",
    "\n",
    "%pip install langgraph\n",
    "%pip install --upgrade \\\n",
    "    langchain==0.1.14 \\\n",
    "    langchain-core==0.1.31 \\\n",
    "    langchain-openai==0.1.3\n",
    "%pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b3356",
   "metadata": {},
   "source": [
    "#### 기본 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6fba95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a764cf",
   "metadata": {},
   "source": [
    "##### LLM 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8129f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7131d77f",
   "metadata": {},
   "source": [
    "##### 상태정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be5e96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class QuestionState(TypedDict):\n",
    "    messages: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc76507",
   "metadata": {},
   "source": [
    "##### Agent / Tool Prompt 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b975a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "question_agent_prompt = \"\"\"\n",
    "your are a question agent app only can do an operation if you need other then call other app. Use Korean Language.\n",
    "\"\"\"\n",
    "\n",
    "mesage_context_prompt = \"\"\"\n",
    "This tool is a wrapper for answering messages.\n",
    "\n",
    "**VERY IMPORTANT**  \n",
    "Your input to this tool MUST message and string type. \n",
    "\n",
    "**Don't change result of json result by your self, Just return exact result.**\n",
    "**Response format :** should be in JSON String.\n",
    "\"\"\"\n",
    "\n",
    "class MessageContext(BaseModel):\n",
    "    messages: str = Field(..., description=\"messages\")\n",
    "\n",
    "def anwser_tool(messages) -> dict:\n",
    "    result = llm.invoke(messages)\n",
    "    print(result)\n",
    "\n",
    "    return {\n",
    "        \"messages\" : [\n",
    "            result\n",
    "        ],\n",
    "    }\n",
    "\n",
    "agent_tools = [\n",
    "                StructuredTool.from_function(\n",
    "                    anwser_tool, \n",
    "                    name=\"anwser\", \n",
    "                    description=mesage_context_prompt, \n",
    "                    args_schema=MessageContext\n",
    "                )\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100e877",
   "metadata": {},
   "source": [
    "##### Agent 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9f0e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "\n",
    "def answer_question_agent_dict(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "\n",
    "    # 기본적으로 출력되는 메시지\n",
    "    output_state = {\n",
    "        \"messages\": [HumanMessage(content=result[\"output\"], name=name)]\n",
    "    }\n",
    "    return output_state\n",
    "\n",
    "\n",
    "def answer_question_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an app.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604771ae",
   "metadata": {},
   "source": [
    "##### Graph Build "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "983f3300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='안녕하세요! 무엇을 도와드릴까요?', additional_kwargs={}, response_metadata={}, name='answer_question')]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.graph import StateGraph\n",
    "import functools\n",
    "  \n",
    "\n",
    "workflow_graph_builder = StateGraph(QuestionState)\n",
    "    \n",
    "workflow_graph_builder.add_node(\n",
    "    \"answer_question\", \n",
    "    functools.partial(\n",
    "        answer_question_agent_dict, \n",
    "        agent=answer_question_agent(\n",
    "            llm=llm,\n",
    "            tools=agent_tools, \n",
    "            system_message=question_agent_prompt\n",
    "        ), \n",
    "        name=\"answer_question\"\n",
    "    )\n",
    ")\n",
    "\n",
    "workflow_graph_builder.add_edge(START, \"answer_question\")\n",
    "workflow_graph_builder.add_edge(\"answer_question\", END)\n",
    "\n",
    "workflow_app = workflow_graph_builder.compile()\n",
    "\n",
    "result = workflow_app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"안녕하세요?\")]\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
