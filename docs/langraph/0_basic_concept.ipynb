{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daf1a4f3",
   "metadata": {},
   "source": [
    "# 의존성 설치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c197dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# update or install the necessary libraries\n",
    "\n",
    "%pip install langgraph\n",
    "%pip install --upgrade \\\n",
    "    langchain==0.1.14 \\\n",
    "    langchain-core==0.1.31 \\\n",
    "    langchain-openai==0.1.3\n",
    "%pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4622fb",
   "metadata": {},
   "source": [
    "# Langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c72ab3",
   "metadata": {},
   "source": [
    "## Conventional RAG 문제점 \n",
    "\n",
    "- 전에 정의된 데이터 소싱(PDF, DB, Table) 자원 \n",
    "- 사전에 정의된 Fixed Size Chunk \n",
    "- 사전에 정의된 검색 방법 \n",
    "- 신뢰하기 어려운 LLM 혹은 Agent \n",
    "- 고정된 프롬프트 양식 \n",
    "- LLM의 답변 결과에 대한 문서와의 관련성/신뢰성\n",
    "\n",
    "### 문제라고 볼 수 있는 부분들 \n",
    "\n",
    "- Document Loader(데이터 로드) > Answer(답변) \n",
    "- RAG 파이프라인이 단방향 구조이기 때문\n",
    "\n",
    "- 모든 단계를 한 번에 다 잘해야 함 \n",
    "- 이전 단계로 되돌아가기 어려움 \n",
    "  - 이전 과정의 결과물을 수정하기 어려움 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f136bb6",
   "metadata": {},
   "source": [
    "# 개선해볼 수 있는 방향 \n",
    "\n",
    "- Langgraph를 이용해서 RAG 파이프라인을 보다 유연하게 설계 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046425f",
   "metadata": {},
   "source": [
    "# LangGraph 제안 \n",
    "\n",
    "- 평가자 & Query Transform 제안 \n",
    "\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    Question[질문<br/>Question]\n",
    "    Retrieve[문서 검색<br/>Retrieve]\n",
    "    Evaluator((평가자<br/>Evaluator))\n",
    "    QueryRewrite[질문 재작성<br/>Query Rewrite]\n",
    "    LLM[답변 생성<br/>LLM]\n",
    "    Answer[최종답변<br/>Answer]\n",
    "\n",
    "    Question --> Retrieve\n",
    "    Retrieve --> Evaluator\n",
    "    Evaluator -- Check Fail --> QueryRewrite\n",
    "    QueryRewrite --> Question\n",
    "    Evaluator -- Pass --> LLM\n",
    "    LLM --> Answer\n",
    "```\n",
    "\n",
    "- 추가 검색기를 통하여 문맥(context) 보강 \n",
    "\n",
    "```mermaid \n",
    "flowchart LR\n",
    "    Question[질문<br/>Question]\n",
    "    Retrieve[문서 검색<br/>Retrieve]\n",
    "    LLM[답변 생성<br/>LLM]\n",
    "    Answer[최종답변<br/>Answer]\n",
    "    Evaluator((평가자<br/>Evaluator))\n",
    "    QueryRewrite[질문 재작성<br/>Query Rewrite]\n",
    "    WebSearch[웹 검색<br/>Web Search]\n",
    "\n",
    "    Question --> Retrieve\n",
    "    Retrieve --> LLM\n",
    "    LLM --> Evaluator\n",
    "    Evaluator -- Pass --> Answer\n",
    "    Evaluator -- Check Fail --> QueryRewrite\n",
    "    QueryRewrite --> Question\n",
    "    Evaluator -- Suggest --> WebSearch\n",
    "    WebSearch --> Retrieve\n",
    "    WebSearch -- Add Context --> Retrieve\n",
    "```\n",
    "\n",
    "- 문서-답변 간 관련성 여부를 판단하는 평가자2 를 추가하여 검증 \n",
    "\n",
    "```mermaid \n",
    "flowchart LR\n",
    "    Question[질문<br/>Question]\n",
    "    Retrieve[문서 검색<br/>Retrieve]\n",
    "    Eval1((평가자 1<br/>Evaluator))\n",
    "    WebSearch[웹 검색<br/>Web Search]\n",
    "    QueryRewrite[질문 재작성<br/>Query Rewrite]\n",
    "    LLM[답변 생성<br/>LLM]\n",
    "    Eval2((평가자 2<br/>Relevance))\n",
    "    Answer[최종답변<br/>Answer]\n",
    "\n",
    "    Question --> Retrieve\n",
    "    Retrieve --> Eval1\n",
    "    Eval1 -- Add Context --> WebSearch\n",
    "    WebSearch --> Retrieve\n",
    "    WebSearch --> QueryRewrite\n",
    "    QueryRewrite --> Question\n",
    "\n",
    "    Eval1 --> LLM\n",
    "    LLM --> Eval2\n",
    "    Eval2 -- pass --> Answer\n",
    "    Eval2 -- Check Fail --> WebSearch\n",
    "    Eval2 -- re-generate --> LLM\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da785de",
   "metadata": {},
   "source": [
    "## Langgraph의 중요 개념 \n",
    "\n",
    "- Node(노드), Edge(엣지), State(상태관리)를 통해 LLM을 활용한 워크플로우에 순환(Cycle) 연산 기능을 추가하여 손쉽게 흐름을 제어\n",
    "- RAG 파이프라인의 세부 단계별 흐름제어가 가능 \n",
    "- Conditional Edge: 조건부 (if, elif, else 와 같은..)흐름 제어 \n",
    "- Human-in-the-loop: 필요시 중간 개입하여 다음 단계를 결정 \n",
    "- Checkpointer: 과거 실행과정에 대한 \"수정\"&\"리플레이\" 기능 \n",
    "\n",
    "### 각 용어의 의미 \n",
    "\n",
    "- Node : 어떤 작업을 수행할지 정의 \n",
    "- Edge : 다음으로 실행할 동작 정의 \n",
    "- State : 현재의 상태 값을 저장 및 전달하는데 활용 \n",
    "- Conditional Edge : 조건에 따라 분기 처리 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31d9b3",
   "metadata": {},
   "source": [
    "## 상태 - State\n",
    "\n",
    "- TypedDict: 일반 파이썬 dict에 타입힌팅을 추가한 개념이지만, 쉽게 Ditionary로 생각해도 좋습니다. \n",
    "- 모든 값을 다 채우지 않아도 됩니다. \n",
    "- 새로운 노드에서 값을 덮어쓰기 방식으로 채웁니다. \n",
    "- Reducer(add_messages 혹은 operator.add): 자동으로 list에 메세지를 추가해주는 기능 \n",
    "\n",
    "노드와 노드 사이의 정보를 전달할 때 사용가능하며, 꼭 내용을 다 채워야할 필요는 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b4f7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict \n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class GraphState(TypedDict): \n",
    "  question: Annotated[list, add_messages]\n",
    "  context: Annotated[str, \"Context\"]\n",
    "  answer: Annotated[str, \"Answer\"]\n",
    "  messages: Annotated[list, add_messages]\n",
    "  relevance: Annotated[str, \"Relevance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133337c1",
   "metadata": {},
   "source": [
    "### Reducer\n",
    "\n",
    "- Reducer (add_messages 혹은 operator.add): 자동으로 list에 메시지를 추가한다. \n",
    "  - `left` (Messages) : 기본 메시지 리스트 \n",
    "  - `right` (Messages) : 병합할 메시지 리스트 또는 단일 메시지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb791704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='안녕하세요?', additional_kwargs={}, response_metadata={}, id='1'), AIMessage(content='반갑습니다~', additional_kwargs={}, response_metadata={}, id='2')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langgraph.graph import add_messages\n",
    "\n",
    "msgs1 = [HumanMessage(content=\"안녕하세요?\", id=\"1\")]\n",
    "msgs2 = [AIMessage(content=\"반갑습니다~\", id=\"2\")]\n",
    "\n",
    "result1 = add_messages(msgs1, msgs2)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcfbffc",
   "metadata": {},
   "source": [
    "### 노드별 상태 값의 변화 \n",
    "\n",
    "- 각 노드에서 업데이트 하는 값은 State에 대해서 기존 Key 값을 덮어쓰는 방식 \n",
    "- 노드에서 필요한 상태 값을 조회하여 동작에 활용할 수 있음\n",
    "- 각 노드의 진행 단계에 따라서 State가 변하게 되고, 각기 값에 대해서 우리가 필요한 경우 평가를 통해서 \n",
    "  - 질문 재작성 요청 \n",
    "  - 문서를 다시 검색 / 검색을 통한 정보 보완 \n",
    "  - 답변을 재작성 요청 \n",
    "- 원하는 방식에 따라서 State를 상태를 공유하여 내부 흐름을 제어할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b811cf7",
   "metadata": {},
   "source": [
    "## 노드(Node) & 엣지(Edge) & 조건부 엣지\n",
    "\n",
    "### 노드 \n",
    "\n",
    "- 함수 정의 \n",
    "- 입력인자 : 상태(State) 객체 \n",
    "- 입력과 출력은 상태가 되어야한다. \n",
    "\n",
    "### Edge\n",
    "\n",
    "- 노드에서 노드간의 연결 \n",
    "- add_edge(\"노드 이름\", \"노드 이름\")\n",
    "  - from > to \n",
    "\n",
    "### 조건부 엣지 \n",
    "\n",
    "- LLM as Judge를 이용해서 평가를 수행한 다음에 기준의 점수에 못칠때, 조건부 엣지를 효과적으로 활용이 가능하다. \n",
    "- 노드에 조건부 엣지를 추가하여 분기를 수행할 수 있습니다.\n",
    "- add_conditional_edges는 (\"노드이름\", 조건부 판단 함수, dict 로 다음 단계 결정)\n",
    "\n",
    "### 시작점 지정 \n",
    "\n",
    "### 체크 포인터 ( Memory )\n",
    "\n",
    "- Checkpointer : 각 노드간 실행 결과를 추적하기 위한 메모리 \n",
    "- 체크 포인터를 활용하여 특정 시점으로 되돌리기도 가능\n",
    "- compile(checkpoint=memory) 지정하여 그래프 생성 \n",
    "\n",
    "### 그래프 실행 \n",
    "\n",
    "- RunnableConfig \n",
    "  - recursion_limit : 최대 노드 개수를 지정합니다. \n",
    "  - thread_id : 그래프 실행 아이디를 기록하고, 추후 추적하기 위한 목적으로 활용합니다. \n",
    "- 상태로 시작합니다. \n",
    "  - 여기어 \"question\"에 대한 질문만 입력하고 상태를 첫번째 노드에게 전달합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "workflow.add_node(\"retrieve\", retrieve_document)\n",
    "workflow.add_node(\"llm_answer\", llm_answer)\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"llm_answer\")\n",
    "\n",
    "def is_relevant(state: GraphState):\n",
    "  question = \",\".join([humanMessage.content for humanMessage in state[\"question\"]])\n",
    "  answer = \",\".join([humanMessage.content for humanMessage in state[\"answer\"]])\n",
    "  message= f\"\"\" \n",
    "    다음 요청은 질문과 답변에 대해서 적합할지 추론해줘\n",
    "    만약 적합하다면 True, 적합하지 않다면 False로 대답해 주세요.\n",
    "    **사용자의 질문**과 **대화의 답변**을 기반으로 합리적으로 추론해주세요.\n",
    "    \n",
    "    # 요청 하는 의미: \n",
    "    ## 사용자의 질문 : {question}\n",
    "    ## 대화의 답변 : {answer}\n",
    "    \n",
    "    # 요청에 대한 답변:\n",
    "    Boolean\n",
    "\n",
    "    반드시 Boolean 으로만 대답해 주세요. 반드시 true 또는 false로 입력해주세요.\n",
    "    I will give a 100$ tip for the best answer.\n",
    "  \"\"\"\n",
    "\n",
    "  response = llm.invoke([HumanMessage(content=message)])\n",
    "  if \"true\" in response.content:\n",
    "    return \"grouned\"\n",
    "  else:\n",
    "    return \"notGrounded\"\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "  \"retrieve\",\n",
    "  is_relevant, \n",
    "  {\n",
    "    \"grouned\" : END, \n",
    "    \"notGrounded\" : \"llm_asnwer\",\n",
    "    \"notSure\": \"llm_answer\"\n",
    "  }\n",
    ")\n",
    "\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "config = RunnableConfig(recursion_limit=4, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "inputs = GraphState(question=\"삼성전자가 개발한 생성형 AI의 이름은?\")\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "display(\n",
    "  Image(app.get_graph(xray=True).draw_mermaid_png())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550609a",
   "metadata": {},
   "source": [
    "# References \n",
    "\n",
    "- [#Langrapg 개념 완전 정복 몰아보기(3시간)](https://www.youtube.com/watch?v=W_uwR_yx4-c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
